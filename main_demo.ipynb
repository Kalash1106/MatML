{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loading the Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "def load_classification_model(weights_path):\n",
    "    model = torchvision.models.resnet34()\n",
    "    model.fc = nn.Sequential(nn.Linear(model.fc.in_features, 128),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.4),\n",
    "                            nn.Linear(128, 2))\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'weights\\resnet34.pth'\n",
    "model = load_classification_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Model Inference </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your Google API Key\n",
    "import google.generativeai as genai\n",
    "\n",
    "GOOGLE_API_KEY = \n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gemini(img) -> str:\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            \"You are a smart and precise AI engine that can understand the defects in materials.\",\n",
    "            img,\n",
    "            \"Describe the material defect in 50 this image. Briefly cover the important details, causes and effects. Stricty limit your answer to 50 words\",\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    complete_respose = str()\n",
    "    for chunk in response:\n",
    "        complete_respose += chunk.text\n",
    "\n",
    "    return complete_respose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def inference(PIL_image, img_tensor, model, threshold):\n",
    "    logits = model(img_tensor)\n",
    "\n",
    "    #Non defective condition\n",
    "    if (logits[0][1] - logits[0][0]).item() >= math.log(threshold/(1-threshold)):\n",
    "        return \"The item in this image does not contain any visible defects\"\n",
    "    else:\n",
    "        return prompt_gemini(PIL_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def predict_image(image, threshold = 0.7):\n",
    "    PIL_image = Image.fromarray(image)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize input images to a size larger than the required crop size\n",
    "        transforms.CenterCrop(227),     # Crop the center region of the resized image\n",
    "        transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "    ])\n",
    "\n",
    "    input_tensor = transform(PIL_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Make a prediction\n",
    "    with torch.no_grad():\n",
    "        return inference(PIL_image, input_batch, model, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/16 12:58:22 [W] [service.go:132] login to server failed: dial tcp 44.237.78.176:7000: i/o timeout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Image(),\n",
    "    outputs=gr.Textbox(label=\"Image Diagnosis\"),\n",
    "    title=\"MatLLM - Defect Classification & Description\",\n",
    "    description=\"Upload an image and the model will classify/describe it.\",\n",
    "    theme=\"default\",\n",
    "    css=\"\"\"\n",
    "        /* Style the output box */\n",
    "        .gr-output-text {\n",
    "        background-color: #f5f5f5;\n",
    "        padding: 10px;\n",
    "        border: 1px solid #ddd;\n",
    "        border-radius: 4px;\n",
    "        font-size: 16px;\n",
    "        }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio application\n",
    "app.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
